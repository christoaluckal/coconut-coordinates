{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# To add a new cell, type '# %%'\n",
        "# To add a new markdown cell, type '# %% [markdown]'\n",
        "# %% [markdown]\n",
        "# ### Use this Jupyter Notebook as a guide to run your trained model in inference mode\n",
        "# \n",
        "# created by Anton Morgunov\n",
        "# \n",
        "# inspired by [tensorflow object detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model)\n",
        "# %% [markdown]\n",
        "# Your first step is going to specify which unit you are going to work with for inference. Select between GPU or CPU and follow the below instructions for implementation."
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os # importing OS in order to make GPU visible\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # do not change anything in here\n",
        "\n",
        "# specify which device you want to work on.\n",
        "# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" # TODO: specify your computational device\n"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf # import tensorflow\n",
        "\n",
        "# checking that GPU is found\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU found')\n",
        "else:\n",
        "    print(\"No GPU found\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU found\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# other import\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# %% [markdown]\n",
        "# Next you will import import scripts that were already provided by Tensorflow API. **Make sure that Tensorflow is your current working directory.**"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys # importyng sys in order to access scripts located in a different folder\n",
        "\n",
        "path2scripts = 'models/research/' # TODO: provide pass to the research folder\n",
        "sys.path.insert(0, path2scripts) # making scripts in models/research available for import\n"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# importing all scripts that will be needed to export your model and use it for inference\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n"
      ],
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Now you can import and build your trained model:\n"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NOTE: your current working directory should be Tensorflow.\n",
        "\n",
        "# TODO: specify two pathes: to the pipeline.config file and to the folder with trained model.\n",
        "path2config ='/home/christo/Desktop/sshrepo/coconut-detection/workspace_neptune/models/my_ssd/pipeline.config' #CHANGE\n",
        "path2model = '/home/christo/Desktop/sshrepo/coconut-detection/workspace_neptune/exported_models/' #CHANGE\n"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# do not change anything in this cell\n",
        "configs = config_util.get_configs_from_pipeline_file(path2config) # importing config\n",
        "model_config = configs['model'] # recreating model config\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False) # importing model\n"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore('/home/christo/Desktop/sshrepo/coconut-detection/workspace_neptune/exported_models/checkpoint/ckpt-0').expect_partial() #CHANGE\n",
        "\n",
        "# %% [markdown]\n",
        "# Next, path to label map should be provided. Category index will be created based on labal map file"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe5b47447f0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path2label_map = '/home/christo/Desktop/sshrepo/coconut-detection/workspace_neptune/data/label_map.pbtxt' #CHANGE\n",
        "category_index = label_map_util.create_category_index_from_labelmap(path2label_map,use_display_name=True)\n",
        "\n",
        "# %% [markdown]\n",
        "# Now, a few supporting functions will be defined"
      ],
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def detect_fn(image):\n",
        "    \"\"\"\n",
        "    Detect objects in image.\n",
        "    \n",
        "    Args:\n",
        "      image: (tf.tensor): 4D input image\n",
        "      \n",
        "    Returs:\n",
        "      detections (dict): predictions that model made\n",
        "    \"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections\n"
      ],
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "# %% [markdown]\n",
        "# **Next function is the one that you can use to run inference and plot results an an input image:**\n",
        "# %% [markdown]\n",
        "# Next, we will define a few other supporting functions:"
      ],
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def nms(rects, thd=0.5):\n",
        "    \"\"\"\n",
        "    Filter rectangles\n",
        "    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
        "    thd - intersection threshold (intersection divides min square of rectange)\n",
        "    \"\"\"\n",
        "    out = []\n",
        "\n",
        "    remove = [False] * len(rects)\n",
        "\n",
        "    for i in range(0, len(rects) - 1):\n",
        "        if remove[i]:\n",
        "            continue\n",
        "        inter = [0.0] * len(rects)\n",
        "        for j in range(i, len(rects)):\n",
        "            if remove[j]:\n",
        "                continue\n",
        "            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n",
        "\n",
        "        max_prob = 0.0\n",
        "        max_idx = 0\n",
        "        for k in range(i, len(rects)):\n",
        "            if inter[k] >= thd:\n",
        "                if rects[k][1] > max_prob:\n",
        "                    max_prob = rects[k][1]\n",
        "                    max_idx = k\n",
        "\n",
        "        for k in range(i, len(rects)):\n",
        "            if (inter[k] >= thd) & (k != max_idx):\n",
        "                remove[k] = True\n",
        "\n",
        "    for k in range(0, len(rects)):\n",
        "        if not remove[k]:\n",
        "            out.append(rects[k])\n",
        "\n",
        "    boxes = [box[0] for box in out]\n",
        "    scores = [score[1] for score in out]\n",
        "    classes = [cls[2] for cls in out]\n",
        "    return boxes, scores, classes\n",
        "\n",
        "\n",
        "def intersection(rect1, rect2):\n",
        "    \"\"\"\n",
        "    Calculates square of intersection of two rectangles\n",
        "    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n",
        "    return: square of intersection\n",
        "    \"\"\"\n",
        "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n",
        "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n",
        "    overlapArea = x_overlap * y_overlap;\n",
        "    return overlapArea\n",
        "\n",
        "\n",
        "def square(rect):\n",
        "    \"\"\"\n",
        "    Calculates square of rectangle\n",
        "    \"\"\"\n",
        "    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])\n",
        "\n",
        "# %% [markdown]\n",
        "# **Next function is the one that you can use to run inference and save results into a file:**"
      ],
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def inference_as_raw_output(path2images,box_th = 0.25,nms_th = 0.5,to_file = False,data = None,path2dir = False):\n",
        "    \"\"\"\n",
        "    Function that performs inference and return filtered predictions\n",
        "    \n",
        "    Args:\n",
        "      path2images: an array with pathes to images\n",
        "      box_th: (float) value that defines threshold for model prediction. Consider 0.25 as a value.\n",
        "      nms_th: (float) value that defines threshold for non-maximum suppression. Consider 0.5 as a value.\n",
        "      to_file: (boolean). When passed as True => results are saved into a file. Writing format is\n",
        "      path2image + (x1abs, y1abs, x2abs, y2abs, score, conf) for box in boxes\n",
        "      data: (str) name of the dataset you passed in (e.g. test/validation)\n",
        "      path2dir: (str). Should be passed if path2images has only basenames. If full pathes provided => set False.\n",
        "      \n",
        "    Returs:\n",
        "      detections (dict): filtered predictions that model made\n",
        "    \"\"\"\n",
        "    \n",
        "    print (f'Current data set is {data}')\n",
        "    print (f'Ready to start inference on {len(path2images)} images!')\n",
        "    \n",
        "    for image_path in tqdm(path2images):\n",
        "        if path2dir: # if a path to a directory where images are stored was passed in\n",
        "            image_path = os.path.join(path2dir, image_path.strip())\n",
        "            \n",
        "        image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "        detections = detect_fn(input_tensor)\n",
        "        \n",
        "        # checking how many detections we got\n",
        "        num_detections = int(detections.pop('num_detections'))\n",
        "        \n",
        "        # filtering out detection in order to get only the one that are indeed detections\n",
        "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
        "        \n",
        "        # detection_classes should be ints.\n",
        "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "        \n",
        "        # defining what we need from the resulting detection dict that we got from model output\n",
        "        key_of_interest = ['detection_classes', 'detection_boxes', 'detection_scores']\n",
        "        \n",
        "        # filtering out detection dict in order to get only boxes, classes and scores\n",
        "        detections = {key: value for key, value in detections.items() if key in key_of_interest}\n",
        "        \n",
        "        if box_th: # filtering detection if a confidence threshold for boxes was given as a parameter\n",
        "            for key in key_of_interest:\n",
        "                scores = detections['detection_scores']\n",
        "                current_array = detections[key]\n",
        "                filtered_current_array = current_array[scores > box_th]\n",
        "                detections[key] = filtered_current_array\n",
        "        \n",
        "        if nms_th: # filtering rectangles if nms threshold was passed in as a parameter\n",
        "            # creating a zip object that will contain model output info as\n",
        "            output_info = list(zip(detections['detection_boxes'],\n",
        "                                   detections['detection_scores'],\n",
        "                                   detections['detection_classes']\n",
        "                                  )\n",
        "                              )\n",
        "            boxes, scores, classes = nms(output_info)\n",
        "            \n",
        "            detections['detection_boxes'] = boxes # format: [y1, x1, y2, x2]\n",
        "            detections['detection_scores'] = scores\n",
        "            detections['detection_classes'] = classes\n",
        "            \n",
        "        if to_file and data: # if saving to txt file was requested\n",
        "\n",
        "            image_h, image_w, _ = image_np.shape\n",
        "            file_name = f'pred_result_{data}.txt'\n",
        "            \n",
        "            line2write = list()\n",
        "            line2write.append(os.path.basename(image_path))\n",
        "            \n",
        "            with open(file_name, 'a+') as text_file:\n",
        "                # iterating over boxes\n",
        "                for b, s, c in zip(boxes, scores, classes):\n",
        "                    \n",
        "                    y1abs, x1abs = b[0] * image_h, b[1] * image_w\n",
        "                    y2abs, x2abs = b[2] * image_h, b[3] * image_w\n",
        "                    \n",
        "                    list2append = [x1abs, y1abs, x2abs, y2abs, s, c]\n",
        "                    line2append = ','.join([str(item) for item in list2append])\n",
        "                    \n",
        "                    line2write.append(line2append)\n",
        "                \n",
        "                line2write = ' '.join(line2write)\n",
        "                text_file.write(line2write + os.linesep)\n",
        "        \n",
        "        return detections\n"
      ],
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def inference_with_plot(path2images,outputs,count=0, box_th=0.33,iou_threshold=0.1):\n",
        "    \"\"\"\n",
        "    Function that performs inference and plots resulting b-boxes\n",
        "    \n",
        "    Args:\n",
        "      path2images: an array with pathes to images\n",
        "      box_th: (float) value that defines threshold for model prediction.\n",
        "      \n",
        "    Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "    print(path2images)\n",
        "    for image_path in path2images:\n",
        "\n",
        "        print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "        image_np = load_image_into_numpy_array(image_path)\n",
        "        \n",
        "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "        detections = detect_fn(input_tensor)\n",
        "\n",
        "        # All outputs are batches tensors.\n",
        "        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "        # We're only interested in the first num_detections.\n",
        "        num_detections = int(detections.pop('num_detections'))\n",
        "        detections = {key: value[0, :num_detections].numpy()\n",
        "                      for key, value in detections.items()}\n",
        "        \n",
        "        detections['num_detections'] = num_detections\n",
        "\n",
        "        # detection_classes should be ints.\n",
        "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "        selected_indices = tf.image.non_max_suppression(boxes=detections['detection_boxes'], max_output_size=100, iou_threshold=0.01,scores=detections['detection_scores'])\n",
        "        boxes = tf.gather(detections['detection_boxes'],selected_indices).numpy()\n",
        "        scores = tf.gather(detections['detection_scores'],selected_indices).numpy()\n",
        "        fin_boxes = []\n",
        "        for i in range(0,scores.shape[0]):\n",
        "          if scores[i] > box_th:\n",
        "            fin_boxes.append(boxes[i].tolist())\n",
        "        if(len(fin_boxes)!=0):\n",
        "          label_id_offset = 1\n",
        "          image_np_with_detections = image_np.copy()\n",
        "          viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                  image_np_with_detections,\n",
        "                  boxes,\n",
        "                  detections['detection_classes']+label_id_offset,\n",
        "                  scores,\n",
        "                  category_index,\n",
        "                  use_normalized_coordinates=True,\n",
        "                  max_boxes_to_draw=200,\n",
        "                  min_score_thresh=box_th,\n",
        "                  agnostic_mode=False,\n",
        "                  line_thickness=5)\n",
        "\n",
        "          # plt.figure(figsize=(15,10))\n",
        "          # plt.imshow(image_np_with_detections)\n",
        "          plt.imsave(outputs+'/op{}.png'.format(count),image_np_with_detections) #CHANGE\n",
        "          print('Done')\n",
        "          return fin_boxes\n",
        "        else:\n",
        "          break\n"
      ],
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "import image\n",
        "import sys\n",
        "args = sys.argv[1:]\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "img_name = args[0]\n",
        "op_path = args[1]\n",
        "sp_path = args[2]\n",
        "count = 0\n",
        "t_img = [img_name] #CHANGE\n",
        "choice = input(print(\"Do you want to break up the image? y/n\"))\n",
        "if choice == 'n':\n",
        "    start = time.time()\n",
        "    box_list = inference_with_plot(t_img,op_path,box_th=0.35)\n",
        "    end = time.time()\n",
        "    print(box_list)\n",
        "    print(end-start)\n",
        "else:\n",
        "    start = time.time()\n",
        "    img_name_list = image.breakImage(t_img[0],sp_path)\n",
        "    # print(img_list)\n",
        "    for x in img_name_list:\n",
        "        box_list = inference_with_plot([x],op_path,count,box_th=0.20)\n",
        "        print(box_list)\n",
        "        count+=1\n",
        "    end = time.time()\n",
        "    print(end-start)\n",
        "# inference_as_raw_output(new_img,to_file=True,data=\"test\")\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8cbd6624aea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mop_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#CHANGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}